---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---



* **Seleted Publications** 


* **Junfeng Gao**, Jesper Cairo Westergaard, Ea Høegh Riis Sundmark, Merethe Bagge, Erland Liljeroth, Erik Alexandersson; Automatic late blight lesion recognition and severity quantification based on field imagery of diverse potato genotypes by deep learning, Knowledge-based Systems, 2021, 214, 106723.

* **Junfeng Gao**, Andrew French, Michael Pound, Tony Pridmore, Jan Pieters. Deep convolutional neural networksfor image-basedConvolvulus sepiumdetection in sugar beet fields, Plant Methods, 2020,16, 29. 

* Yanchao Zhang*, **Junfeng Gao***, Haiyan Cen, Yongliang Lu, Xiaoyue Yu, Yong He, Jan G. Pieters; Automated spectral feature extraction from hyperspectral images to differentiate weedy rice and barnyard grass from a rice crop. Computers and Electronics in Agriculture, 2019, 159, 42-49. 

* **Junfeng Gao**, Wenzhi Liao, David Nuyttens, Peter Lootens,  Jürgen Vangeyte, Aleksandra Pižurica, Jan G Pieters. Fusion of pixel and object-based features for weed mapping using unmanned aerial vehicle imagery. International journal of applied earth observation and geoinformation, 2018, 67, 43-53.

* **Junfeng Gao**, David Nuyttens, Peter Lootens, Jan G. Pieters. Recognising weeds in a maize crop using a random forest machine-learning algorithmand near-infrared snapshot mosaic hyperspectral imagery. Biosystems Engineering,2018, 170,39-50.

* Ziyi Liu, **Junfeng Gao**, Guoguo Yang, Huan Zhang, Yong He. Localization and Classification of Paddy Field Pests using a Saliency Map and Deep Convolutional Neural Network.Scientific reports,2016,6,1-12.

* **Junfeng Gao**, Xiaoli Li, Fengle Zhu, Yong He. Application of hyperspectral imaging technology to discriminate different geographical origins of Jatropha curcas L. seedsComputers and Electronics in Agriculture, 2013,99, 186-193.










<!-- 
* **Zhu, Z.** and Hu, H. (2018). Robot learning from demonstration in robotic assembly: A survey. <var>Robotics</var>, 7(2):17.
    * Learning from demonstration (LfD) has been used to help robots to implement manipulation tasks autonomously, in particular, to learn manipulation behaviours from observing the motion executed by human demonstrators. This paper reviews recent research and development in the field of LfD. The main focus is placed on how to demonstrate the example behaviours to the robot in assembly operations, and how to extract the manipulation features for robot learning and generating imitative behaviours. Diverse metrics are analysed to evaluate the performance of robot imitation learning. Specifically, the application of LfD in robotic assembly is a focal point in this paper. [Download paper](http://zuyuanzhu.github.io/files/Zhu2018-Survey.pdf)

* **Zhu, Z.**, Hu, H. and Gu, D., 2018, September. Robot Performing Peg-in-Hole Operations by Learning from Human Demonstration. In <var>2018 10th Computer Science and Electronic Engineering Conference (CEEC)</var> (pp. 30-35). IEEE. -->






<!-- {% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %} -->
